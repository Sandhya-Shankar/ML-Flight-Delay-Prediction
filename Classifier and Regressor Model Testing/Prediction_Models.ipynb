{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c5f32f",
   "metadata": {},
   "source": [
    "# ML Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb057051",
   "metadata": {},
   "source": [
    "## Import libraries, get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180b3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a50675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15871fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70dc4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = []\n",
    "l = []\n",
    "for i in range (1,13):\n",
    "    m += [fr\"C:\\Users\\Ram\\Downloads\\2016_original\\2016\\On_Time_On_Time_Performance_2016_{i}\\On_Time_On_Time_Performance_2016_{i}.csv\"]\n",
    "    l += [fr\"C:\\Users\\Ram\\Downloads\\2017_original\\2017\\On_Time_On_Time_Performance_2017_{i}\\On_Time_On_Time_Performance_2017_{i}.csv\"]\n",
    "l = m+l\n",
    "a = [\"ATL\",\"CLT\",\"DEN\",\"DFW\",\"EWR\",\"IAH\",\"JFK\",\"LAS\",\"LAX\",\"MCO\",\"MIA\",\"ORD\",\"PHX\",\"SEA\",\"SFO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901fb3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:4: DtypeWarning: Columns (77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df1 = pd.read_csv(l[0])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n",
      "C:\\Users\\Ram\\AppData\\Local\\Temp\\ipykernel_25840\\2178869117.py:10: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(l[i])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>DepDel15</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>DepDelayMinutes</th>\n",
       "      <th>OriginAirportID</th>\n",
       "      <th>DestAirportID</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>ArrDel15</th>\n",
       "      <th>ArrDelayMinutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>741.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14747</td>\n",
       "      <td>12478</td>\n",
       "      <td>1610.0</td>\n",
       "      <td>1602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14747</td>\n",
       "      <td>12478</td>\n",
       "      <td>1613.0</td>\n",
       "      <td>1602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>743.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14747</td>\n",
       "      <td>12478</td>\n",
       "      <td>1547.0</td>\n",
       "      <td>1602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14747</td>\n",
       "      <td>12478</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>1602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>SEA</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>708.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14747</td>\n",
       "      <td>12478</td>\n",
       "      <td>1524.0</td>\n",
       "      <td>1527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856311</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>4</td>\n",
       "      <td>ORD</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13930</td>\n",
       "      <td>12266</td>\n",
       "      <td>1314.0</td>\n",
       "      <td>1326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856312</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>4</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1156</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12892</td>\n",
       "      <td>11618</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856313</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>4</td>\n",
       "      <td>IAH</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>739.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>737</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12266</td>\n",
       "      <td>11292</td>\n",
       "      <td>904.0</td>\n",
       "      <td>909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856314</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>4</td>\n",
       "      <td>DFW</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11298</td>\n",
       "      <td>11292</td>\n",
       "      <td>1727.0</td>\n",
       "      <td>1747</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856315</th>\n",
       "      <td>2017-12-17</td>\n",
       "      <td>4</td>\n",
       "      <td>MCO</td>\n",
       "      <td>2017</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13204</td>\n",
       "      <td>11618</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>1245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1856316 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FlightDate  Quarter Origin  Year  Month  DayofMonth  DepTime  \\\n",
       "0        2016-01-01        1    SEA  2016      1           1    741.0   \n",
       "1        2016-01-02        1    SEA  2016      1           2    737.0   \n",
       "2        2016-01-03        1    SEA  2016      1           3    743.0   \n",
       "3        2016-01-04        1    SEA  2016      1           4    737.0   \n",
       "4        2016-01-05        1    SEA  2016      1           5    708.0   \n",
       "...             ...      ...    ...   ...    ...         ...      ...   \n",
       "1856311  2017-12-17        4    ORD  2017     12          17   1024.0   \n",
       "1856312  2017-12-17        4    LAX  2017     12          17   1148.0   \n",
       "1856313  2017-12-17        4    IAH  2017     12          17    739.0   \n",
       "1856314  2017-12-17        4    DFW  2017     12          17   1632.0   \n",
       "1856315  2017-12-17        4    MCO  2017     12          17   1007.0   \n",
       "\n",
       "         DepDel15  CRSDepTime  DepDelayMinutes  OriginAirportID  \\\n",
       "0             0.0         745              0.0            14747   \n",
       "1             0.0         745              0.0            14747   \n",
       "2             0.0         745              0.0            14747   \n",
       "3             0.0         745              0.0            14747   \n",
       "4             0.0         710              0.0            14747   \n",
       "...           ...         ...              ...              ...   \n",
       "1856311       0.0        1030              0.0            13930   \n",
       "1856312       0.0        1156              0.0            12892   \n",
       "1856313       0.0         737              2.0            12266   \n",
       "1856314       0.0        1638              0.0            11298   \n",
       "1856315       0.0        1008              0.0            13204   \n",
       "\n",
       "         DestAirportID  ArrTime  CRSArrTime  ArrDel15  ArrDelayMinutes  \n",
       "0                12478   1610.0        1602       0.0              8.0  \n",
       "1                12478   1613.0        1602       0.0             11.0  \n",
       "2                12478   1547.0        1602       0.0              0.0  \n",
       "3                12478   1551.0        1602       0.0              0.0  \n",
       "4                12478   1524.0        1527       0.0              0.0  \n",
       "...                ...      ...         ...       ...              ...  \n",
       "1856311          12266   1314.0        1326       0.0              0.0  \n",
       "1856312          11618   1939.0        2017       0.0              0.0  \n",
       "1856313          11292    904.0         909       0.0              0.0  \n",
       "1856314          11292   1727.0        1747       0.0              0.0  \n",
       "1856315          11618   1222.0        1245       0.0              0.0  \n",
       "\n",
       "[1856316 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['FlightDate',\"Quarter\",\"Origin\",\"Year\",\"Month\",\"DayofMonth\",\"DepTime\",\"DepDel15\",\"CRSDepTime\",\"DepDelayMinutes\",\"OriginAirportID\",\"DestAirportID\",\"ArrTime\",\"CRSArrTime\",\"ArrDel15\",\"ArrDelayMinutes\"]\n",
    "\n",
    "\n",
    "df1 = pd.read_csv(l[0])\n",
    "df1 = df1[df1[\"Origin\"].isin(a)]\n",
    "df1 = df1[df1[\"Dest\"].isin(a)]\n",
    "df1 = df1[df1[\"DepTime\"].notna()]   \n",
    "df1 = pd.DataFrame(df1, columns=columns)\n",
    "for i in range(1,len(l)):\n",
    "    df2 = pd.read_csv(l[i])\n",
    "    df2 = df2[df2[\"Dest\"].isin(a)]\n",
    "    df2 = df2[df2[\"Origin\"].isin(a)]\n",
    "    df2 = df2[df2[\"DepTime\"].notna()]   \n",
    "    df2 = pd.DataFrame(df2, columns=columns)\n",
    "    concat_data = pd.concat([df1, df2], ignore_index=True)\n",
    "    df1 = concat_data\n",
    "\n",
    "\n",
    "\n",
    "# df1 = df1.iloc[:100]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1.to_csv('file1.csv')\n",
    "# Import flight data\n",
    "\n",
    "# df = pd.read_csv(r'C:\\Users\\Ram\\Downloads\\2017_original\\2017\\On_Time_On_Time_Performance_2017_1\\On_Time_On_Time_Performance_2017_1.csv')\n",
    "# columns = ['FlightDate',\"Quarter\",\"Origin\",\"Year\",\"Month\",\"DayofMonth\",\"DepTime\",\"DepDel15\",\"CRSDepTime\",\"DepDelayMinutes\",\"OriginAirportID\",\"DestAirportID\",\"ArrTime\",\"CRSArrTime\",\"ArrDel15\",\"ArrDelayMinutes\"]\n",
    "# df = pd.DataFrame(df, columns=columns)\n",
    "# df =df[df[\"DepTime\"].notna()]\n",
    "\n",
    "# df = df.iloc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4d5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = [\"ATL\",\"CLT\",\"DEN\",\"DFW\",\"EWR\",\"IAH\",\"JFK\",\"LAS\",\"LAX\",\"MCO\",\"MIA\",\"ORD\",\"PHX\",\"SEA\",\"SFO\"]\n",
    "# ll = [\"JFK\"]\n",
    "all_weather_data = {}\n",
    "for i in ll:\n",
    "    city_weather = []\n",
    "    \n",
    "    for j in range(1,13):\n",
    "        city_weather += [f\"C:\\\\Users\\\\Ram\\\\Downloads\\\\{i}\\\\2016-{j}.json\"]\n",
    "        \n",
    "    for j in range(1,13):\n",
    "        city_weather += [f\"C:\\\\Users\\\\Ram\\\\Downloads\\\\{i}\\\\2017-{j}.json\"]\n",
    "    \n",
    "    \n",
    "    \n",
    "    new_json = []\n",
    "    for filename in city_weather:\n",
    "        with open(filename) as fin1:\n",
    "            data1 = json.load(fin1)\n",
    "            data1 = data1['data']['weather']\n",
    "\n",
    "            new_json += [data1]\n",
    "\n",
    "    all_weather_data[i] = new_json\n",
    "\n",
    "with open('all_weather_data.json', 'w+') as f:\n",
    "    json.dump(all_weather_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca7467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('file1.csv',header=0)\n",
    "with open('all_weather_data.json') as f:\n",
    "    all_weather_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9352f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "month = {1:31,2:28,3:31,4:30,5:31,6:30,7:31,8:31,9:30,10:31,11:30,12:31}\n",
    "feb_month = {2016: 29, 2017: 28}\n",
    "flight_weather_data = []\n",
    "\n",
    "for index, row in df1.iterrows():\n",
    "    if df1.at[index,\"DepTime\"] // 100 == 24 :\n",
    "        df1.at[index,\"DayofMonth\"] = df1.at[index,\"DayofMonth\"] + 1\n",
    "        df1.at[index,\"DepTime\"] = df1.at[index,\"DepTime\"] - 2400\n",
    "        if df1.at[index,\"Month\"] == 2:\n",
    "            month[2] = feb_month[df1.at[index,\"Year\"]]\n",
    "        if df1.at[index,\"DayofMonth\"] > month[df1.at[index,\"Month\"]]:\n",
    "            df1.at[index,\"DayofMonth\"] = 1\n",
    "            df1.at[index,\"Month\"] += 1\n",
    "            if df1.at[index,\"Month\"] > 12:\n",
    "                df1.at[index,\"Year\"] += 1\n",
    "                df1.at[index,\"Month\"] = 1\n",
    "    \n",
    "    origin_index = df1.at[index,\"Origin\"]\n",
    "    dep_month_index = (df1.at[index,\"Year\"] - 2016) * 12 + df1.at[index,\"Month\"] - 1\n",
    "    dep_day_index = int(df1.at[index,\"DayofMonth\"]) - 1\n",
    "    dep_time_index = int(df1.at[index,\"DepTime\"] // 100)\n",
    "    \n",
    "    try:\n",
    "        flight_weather = all_weather_data[origin_index][dep_month_index][dep_day_index]['hourly'][dep_time_index]\n",
    "        flight_weather_data.append(flight_weather)        \n",
    "    except:\n",
    "        print('origin_index', origin_index, 'dep_month_index', dep_month_index, '\\tdep_day_index', dep_day_index, '\\tdep_time_index', dep_time_index)\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb694836",
   "metadata": {},
   "outputs": [],
   "source": [
    "windspeedKmphList = [data['windspeedKmph'] for data in flight_weather_data]\n",
    "WindDirDegreeList = [data['winddirDegree'] for data in flight_weather_data]\n",
    "weathercodeList = [data['weatherCode'] for data in flight_weather_data]\n",
    "precipMMList = [data['precipMM'] for data in flight_weather_data]\n",
    "visibilityList = [data['visibility'] for data in flight_weather_data]\n",
    "pressureList = [data['pressure'] for data in flight_weather_data]\n",
    "cloudcoverList = [data['cloudcover'] for data in flight_weather_data]\n",
    "DewPointFList = [data['DewPointF'] for data in flight_weather_data]\n",
    "WindGustKmphList = [data['WindGustKmph'] for data in flight_weather_data]\n",
    "tempFList = [data['tempF'] for data in flight_weather_data]\n",
    "WindChillFList = [data['WindChillF'] for data in flight_weather_data]\n",
    "HumidityList = [data['humidity'] for data in flight_weather_data]\n",
    "timelist = [data['time'] for data in flight_weather_data]\n",
    "\n",
    "\n",
    "df1['windspeedKmph'] = windspeedKmphList\n",
    "df1['winddirDegree'] = WindDirDegreeList\n",
    "df1['weatherCode'] = weathercodeList \n",
    "df1['precipMM'] = precipMMList\n",
    "df1['visibility'] = visibilityList \n",
    "df1['pressure'] = pressureList\n",
    "df1['DewPointF'] = DewPointFList\n",
    "df1['cloudcover'] = cloudcoverList\n",
    "df1['WindGustKmph'] = WindGustKmphList\n",
    "df1['tempF'] = tempFList\n",
    "df1['WindChillF'] = WindChillFList\n",
    "df1['humidity'] = HumidityList\n",
    "df1['time'] = timelist\n",
    "df1=df1.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d0fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1[['Origin', 'weatherCode']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ac68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.to_csv('file2.csv')\n",
    "df1 = pd.read_csv('file2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f892216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification and regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a17bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'X' is your feature matrix and 'y' is your target variable\n",
    "df1 = pd.read_csv('file2.csv')\n",
    "df2 = df1.dropna()\n",
    "X = df2[[\"Year\", \"Month\", \"DayofMonth\", \"DepTime\", \"DepDel15\", \"CRSDepTime\", \"DepDelayMinutes\", \"OriginAirportID\", \"DestAirportID\", \"ArrTime\", \"CRSArrTime\", \"ArrDelayMinutes\", \"windspeedKmph\", \"winddirDegree\", \"weatherCode\", \"precipMM\", \"visibility\", \"pressure\", \"DewPointF\", \"cloudcover\", \"WindGustKmph\", \"tempF\", \"WindChillF\", \"humidity\", \"time\"]]\n",
    "\n",
    "y = df2 [\"ArrDel15\"]\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0532ae9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic REgression\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model using the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the training set\n",
    "y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Predict probabilities on the testing set\n",
    "y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# X_test - no_rows x n_var\n",
    "# 1 row - 1 x n_var\n",
    "# y_pred= model.predict(1 row) -> \n",
    "\n",
    "# Convert probabilities to labels\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R2 score\n",
    "train_r2 = r2_score(y_train, y_train_pred_proba)\n",
    "test_r2 = r2_score(y_test, y_test_pred_proba)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "print(\"Training R2 Score:\", train_r2)\n",
    "print(\"Testing R2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "print(X,y)\n",
    "# Creating a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=1)\n",
    "\n",
    "# Training the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the training set\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculating the training accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculating the test accuracy\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculating the R2 score for training set (classification task, so R2 will be 1.0)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculating the R2 score for test set\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Training R2:\", train_r2)\n",
    "print(\"Test R2:\", test_r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda70870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Extra Trees Classifier\n",
    "\n",
    "\n",
    "clf = ExtraTreesClassifier()\n",
    "\n",
    "# Training the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the training set\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculating the R2 scores\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Printing the accuracy scores and R2 values\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Training R2 Score:\", train_r2)\n",
    "print(\"Test R2 Score:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGB\n",
    "\n",
    "y_classification = df2 [\"ArrDel15\"]\n",
    "y_regression = df2 ['ArrDelayMinutes']\n",
    "# Splitting the preexisting dataset into training and test sets\n",
    "X_train, X_test, y_train_reg, y_test_reg, y_train_cls, y_test_cls = train_test_split(\n",
    "    X, y_regression, y_classification, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "# Convert data to float (if needed)\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "y_train_reg = y_train_reg.astype(float)\n",
    "y_test_reg = y_test_reg.astype(float)\n",
    "\n",
    "# Regression using XGBoost\n",
    "reg_model = xgb.XGBRegressor()\n",
    "reg_model.fit(X_train, y_train_reg)\n",
    "\n",
    "# Predicting on the test set for regression\n",
    "y_test_reg_pred = reg_model.predict(X_test)\n",
    "reg_mse = mean_squared_error(y_test_reg, y_test_reg_pred)\n",
    "\n",
    "# Classification using XGBoost\n",
    "cls_model = xgb.XGBClassifier()\n",
    "cls_model.fit(X_train, y_train_cls)\n",
    "\n",
    "# Predicting on the test set for classification\n",
    "y_test_cls_pred = cls_model.predict(X_test)\n",
    "cls_accuracy = accuracy_score(y_test_cls, y_test_cls_pred)\n",
    "\n",
    "# Printing the MSE value and predicted test values for regression\n",
    "print(\"Regression MSE:\", reg_mse)\n",
    "print(\"Regression Predicted Test Values:\", y_test_reg_pred)\n",
    "\n",
    "# Printing the accuracy score and predicted test values for classification\n",
    "print(\"Classification Accuracy:\", cls_accuracy)\n",
    "print(\"Classification Predicted Test Values:\", y_test_cls_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6672befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest classifier\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Creating a Random Forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Training the classifier on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the training set\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculating the accuracy scores\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Calculating the R2 scores\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# Printing the accuracy scores and R2 values\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Training R2:\", train_r2)\n",
    "print(\"Test R2:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df1.dropna()\n",
    "column_list =[\"Year\", \"Month\", \"DayofMonth\", \"DepTime\", \"DepDel15\", \"CRSDepTime\", \"DepDelayMinutes\", \"OriginAirportID\", \"DestAirportID\", \"ArrTime\", \"CRSArrTime\",\"ArrDel15\", \"windspeedKmph\", \"winddirDegree\", \"weatherCode\", \"precipMM\", \"visibility\", \"pressure\", \"DewPointF\", \"cloudcover\", \"WindGustKmph\", \"tempF\", \"WindChillF\", \"humidity\", \"time\", \"ArrDelayMinutes\"]\n",
    "\n",
    "# Load your dataset into a pandas DataFrame\n",
    "df = pd.read_csv('file2.csv')\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = df[column_list]\n",
    "\n",
    "y = df['ArrDelayMinutes']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab371d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGDRegressor\n",
    "\n",
    "# Feature scaling using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Creating an instance of the SGDRegressor model\n",
    "model = SGDRegressor(max_iter=1000, tol=1e-3)\n",
    "\n",
    "# Training the model on the scaled training data\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the scaled testing data\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the mean squared error (MSE) to evaluate the model's performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "predicted_values = model.predict(X_test_scaled)\n",
    "print(\"Predicted values for the test set:\", predicted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14790f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression\n",
    "\n",
    "\n",
    "# Splitting the preexisting dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Creating a Linear Regression model\n",
    "reg = LinearRegression()\n",
    "\n",
    "# Training the model on the training set\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the training set\n",
    "y_train_pred = reg.predict(X_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_test_pred = reg.predict(X_test)\n",
    "\n",
    "# Calculating the MSE\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Printing the MSE\n",
    "print(\"Train MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "# Printing the predicted test values\n",
    "print(\"Predicted Test Values:\", y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41234bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExtraTrees REgrssion\n",
    "\n",
    "\n",
    "# Splitting the preexisting dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Creating an Extra Trees Regressor\n",
    "regressor = ExtraTreesRegressor()\n",
    "\n",
    "# Training the regressor on the training set\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the training set\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculating the mean squared error (MSE)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Printing the MSE values\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "# Printing the predicted test values\n",
    "print(\"Predicted Test Values:\", y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74bd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "\n",
    "\n",
    "\n",
    "# Splitting the preexisting dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Creating a Random Forest regressor\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "# Training the regressor on the training set\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions on the training set\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculating the mean squared error (MSE)\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Printing the MSE values\n",
    "print(\"Training MSE:\", train_mse)\n",
    "print(\"Test MSE:\", test_mse)\n",
    "\n",
    "# Printing the predicted test values\n",
    "print(\"Predicted Test Values:\")\n",
    "print(y_test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb627044",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
